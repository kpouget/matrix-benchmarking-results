Name:         ssd-inference-2
Namespace:    matrix-benchmarking
Labels:       matrix-benchmarking=true
              matrix-benchmarking-mode=inference
              priorityClassName=build
              project=hello
Annotations:  runai-calculated-status: Running
              runai-current-allocated-gpus: 0.100
              runai-current-allocated-gpus-memory: 1690
              runai-current-requested-gpus: 0.100
              runai-current-requested-gpus-memory: 0
              runai-pending-pods: 0
              runai-podgroup-requested-gpus: 0.100
              runai-podgroup-requested-gpus-memory: 0
              runai-running-pods: 1
              runai-total-requested-gpus: 0.100
              runai-total-requested-gpus-memory: 0
              runai-used-nodes: ip-10-0-147-203.eu-central-1.compute.internal
API Version:  run.ai/v1
Kind:         RunaiJob
Metadata:
  Creation Timestamp:  2022-03-04T14:07:51Z
  Generation:          1
  Managed Fields:
    API Version:  run.ai/v1
    Fields Type:  FieldsV1
    fieldsV1:
      f:metadata:
        f:labels:
          .:
          f:matrix-benchmarking:
          f:matrix-benchmarking-mode:
          f:priorityClassName:
      f:spec:
        .:
        f:template:
          .:
          f:metadata:
            .:
            f:labels:
              .:
              f:job-name:
              f:matrix-benchmarking:
              f:user:
          f:spec:
            .:
            f:containers:
            f:restartPolicy:
            f:schedulerName:
            f:volumes:
    Manager:      kubectl-create
    Operation:    Update
    Time:         2022-03-04T14:07:51Z
    API Version:  run.ai/v1
    Fields Type:  FieldsV1
    fieldsV1:
      f:status:
        .:
        f:active:
        f:startTime:
    Manager:      runaijob-controller
    Operation:    Update
    Subresource:  status
    Time:         2022-03-04T14:07:52Z
    API Version:  run.ai/v1
    Fields Type:  FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .:
          f:runai-calculated-status:
          f:runai-current-allocated-gpus:
          f:runai-current-allocated-gpus-memory:
          f:runai-current-requested-gpus:
          f:runai-current-requested-gpus-memory:
          f:runai-pending-pods:
          f:runai-podgroup-requested-gpus:
          f:runai-podgroup-requested-gpus-memory:
          f:runai-running-pods:
          f:runai-total-requested-gpus:
          f:runai-total-requested-gpus-memory:
          f:runai-used-nodes:
    Manager:         kube-batch
    Operation:       Update
    Time:            2022-03-04T14:08:02Z
  Resource Version:  142416
  UID:               7c661cd5-1c78-43f4-8bd2-254cb2023a99
Spec:
  Template:
    Metadata:
      Annotations:
        Gpu - Fraction:  0.100000
      Labels:
        Job - Name:             ssd-inference-2
        Matrix - Benchmarking:  true
        Project:                hello
        User:                   admin
    Spec:
      Containers:
        Args:
          mkdir /tmp/cfg
cp -v "$SRC_CONFIG_DIR"/* /tmp/cfg
sed -i 's|/data/coco2017_tfrecords|'$STORAGE_DIR'/coco2017_tfrecords|' /tmp/cfg/*
sed -i 's|/checkpoints|'$STORAGE_DIR'/checkpoints|' /tmp/cfg/*

if [[ "inference" == "inference" ]]; then
  count=0
  while true; do
    bash -x examples/SSD320_FP16_inference.sh  /tmp/cfg --raport_file=/tmp/summary.json
    count=$(($count + 1))
    echo "INFERENCE_LOOP_COUNT=$count"
  done
else
  RESULTS_DIR=/tmp/results
  mkdir "$RESULTS_DIR"
  bash -x examples/SSD320_FP16_inference.sh  "$RESULTS_DIR" /tmp/cfg --raport_file=/tmp/summary.json
fi

        Command:
          bash
          -ceuxo
          pipefail
        Env:
          Name:   SRC_CONFIG_DIR
          Value:  /workdir/models/research/configs/
          Name:   STORAGE_DIR
          Value:  /storage
          Name:   reporterGatewayURL
          Value:  runai-prometheus-pushgateway.runai.svc.cluster.local:9091
          Name:   REPORTER_GATEWAY_URL
          Value:  runai-prometheus-pushgateway.runai.svc.cluster.local:9091
          Name:   podUUID
          Value From:
            Field Ref:
              Field Path:  metadata.uid
          Name:            POD_UUID
          Value From:
            Field Ref:
              Field Path:  metadata.uid
          Name:            NODE_NAME
          Value From:
            Field Ref:
              Field Path:   spec.nodeName
        Image:              quay.io/openshift-psap/nvidiadl-ssd-training-benchmark:ssd
        Image Pull Policy:  Always
        Name:               ctr
        Resources:
          Limits:
          Requests:
            Cpu:     100m
            Memory:  10485760
        Volume Mounts:
          Mount Path:  /storage/
          Name:        storage-volume
      Restart Policy:  Never
      Scheduler Name:  runai-scheduler
      Volumes:
        Name:  storage-volume
        Persistent Volume Claim:
          Claim Name:  benchmarking-coco-dataset
Status:
  Active:      1
  Start Time:  2022-03-04T14:07:51Z
Events:
  Type    Reason            Age   From                Message
  ----    ------            ----  ----                -------
  Normal  SuccessfulCreate  30m   runaijobcontroller  Created pod: ssd-inference-2-0-0
