Running non-interactively.
Using the current directory to store the test artifacts (/home/kevin/openshift/matrix_benchmark/results/mpi_benchmark/collective/aws-c4.xlarge/osu-allreduce_4x/run_220220124_1644.dc98).
run ==> 2
cloud ==> aws
machine ==> c4.xlarge
network ==> SDN
env ==> prod
mode ==> collective
operation ==> osu-allreduce
node_count ==> 4
expe ==> collective

mpijob.kubeflow.org "osu-allreduce-2procs" deleted
pod "osu-allreduce-2procs-worker-0" deleted
pod "osu-allreduce-2procs-worker-1" deleted
Waiting for all the MPI Operator pods to disappear ...
Done.
go run apply_template.go -name osu-allreduce -machine c4.xlarge -np 4

Waiting for mpijob.kubeflow.org/osu-allreduce-4procs to complete its execution ...
.....
Done, collecting artifacts in /home/kevin/openshift/matrix_benchmark/results/mpi_benchmark/collective/aws-c4.xlarge/osu-allreduce_4x/run_220220124_1644.dc98 ...

Failed to add the host to the list of known hosts (/root/.ssh/known_hosts).
Failed to add the host to the list of known hosts (/root/.ssh/known_hosts).
Failed to add the host to the list of known hosts (/root/.ssh/known_hosts).
Failed to add the host to the list of known hosts (/root/.ssh/known_hosts).

# OSU MPI Allreduce Latency Test v5.8
# Size       Avg Latency(us)
4                     192.75
8                     181.97
16                    194.83
32                    195.96
64                    177.94
128                   184.62
256                   195.34
512                   198.76
1024                  192.40
2048                  211.05
4096                  228.14
8192                  519.98
16384                 577.82
32768                 703.04
65536                 842.29
131072               1484.81
262144               2307.03
524288               3338.73
1048576              5490.21
All done.
